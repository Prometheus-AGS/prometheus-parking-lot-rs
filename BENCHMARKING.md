# Benchmarking Guide

## Quick Start

```bash
# Run all benchmarks
cargo bench

# Run specific benchmark
cargo bench --bench queue_bench -- queue_enqueue_dequeue

# Test benchmarks without running full analysis
cargo bench --bench queue_bench -- --test
```

## What We Benchmark

### ðŸ“Š Benchmark Coverage

Our comprehensive benchmark suite (`benches/queue_bench.rs`) covers:

1. **Queue Operations** (3 benchmarks)
   - Enqueue/dequeue throughput
   - Priority sorting performance
   - Expired task pruning

2. **Mailbox Operations** (2 benchmarks)
   - Message delivery throughput
   - Message fetch performance

3. **ResourcePool Operations** (4 benchmarks)
   - Immediate task submission
   - Queued task submission
   - Mixed priority scheduling
   - Deadline checking

4. **End-to-End Scenarios** (1 benchmark)
   - Realistic production workload simulation

**Total: 10 comprehensive benchmarks** covering the entire parking lot algorithm.

## Sample Results

Recent benchmark results on Apple M1 Pro:

```
queue_enqueue_dequeue/1000    time: 8.3 ms    thrpt: 120K ops/sec
queue_enqueue_dequeue/10000   time: 726 ms    thrpt: 13.7K ops/sec
mailbox_deliver/1000          time: 2.1 ms    thrpt: 476K ops/sec
pool_submit_immediate/50      time: 1.8 ms
pool_submit_with_queueing/100 time: 3.2 ms    thrpt: 31K ops/sec
```

## Understanding Results

### Throughput Metrics
- **ops/sec**: Operations (enqueue/dequeue) per second
- **elem/s**: Elements (tasks/messages) processed per second
- Higher is better

### Latency Metrics
- **time**: Total time to complete benchmark iteration
- Lower is better
- Watch for consistency across runs

### What to Look For

âœ… **Good Signs**:
- Consistent performance across runs (< 10% variance)
- Linear scaling with task count
- High throughput (> 100K ops/sec for simple operations)

âš ï¸ **Warning Signs**:
- High variance (> 20% difference between runs)
- Non-linear scaling (performance cliff at certain sizes)
- Outliers (some runs much slower than others)

## Comparing Performance

### Baseline Comparison
```bash
# Create baseline
cargo bench --bench queue_bench -- --save-baseline main

# After changes
cargo bench --bench queue_bench -- --baseline main
```

### Cross-Platform Comparison
Results vary by:
- CPU architecture (ARM vs x86)
- CPU speed (single-core performance matters)
- Memory bandwidth
- OS scheduler behavior

Always note your hardware when sharing results.

## Profiling

For deeper analysis:

```bash
# Generate flamegraph (requires cargo-flamegraph)
cargo flamegraph --bench queue_bench -- queue_enqueue_dequeue/10000

# Memory profiling (requires valgrind)
valgrind --tool=massif cargo bench --bench queue_bench -- --test
```

## CI Integration

Add to CI pipeline:
```yaml
- name: Run benchmarks
  run: cargo bench --bench queue_bench -- --test
```

Note: Use `--test` in CI to verify benchmarks compile and run without full statistical analysis (faster).

## Performance Targets

Based on AI agent workload requirements:

| Operation | Target | Current | Status |
|-----------|--------|---------|--------|
| Queue ops | > 100K/s | ~120K/s | âœ… Exceeds |
| Priority sort | < 10ms/1K | ~8ms/1K | âœ… Within |
| Task submit | < 100Î¼s | ~36Î¼s | âœ… Exceeds |
| Mailbox delivery | > 100K/s | ~476K/s | âœ… Exceeds |

## Troubleshooting

### Benchmark Fails to Compile
```bash
# Ensure async feature is enabled
cargo bench --features tokio-runtime
```

### Benchmarks Take Too Long
```bash
# Reduce sample size
cargo bench -- --sample-size 10

# Quick test mode
cargo bench -- --test
```

### Inconsistent Results
- Close other applications
- Disable CPU frequency scaling
- Run multiple times and take average
- Check for thermal throttling

## Further Reading

- [Criterion.rs Documentation](https://bheisler.github.io/criterion.rs/book/)
- [Benchmarking Best Practices](https://easyperf.net/blog/2018/08/26/Microarchitectural-performance-events)
- See `benches/README.md` for detailed benchmark descriptions
